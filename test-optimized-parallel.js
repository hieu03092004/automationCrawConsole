// test-optimized-parallel.js - Test tá»‘i Æ°u cho URLs tá»« Excel
const { fork, execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

async function createOptimizedTestData() {
  console.log('1ï¸âƒ£ Äá»c URLs tá»« file Excel...');
  
  // Sá»­ dá»¥ng npm run split Ä‘á»ƒ Ä‘á»c tá»« Excel
  require('child_process').execSync('npm run split', { stdio: 'inherit' });
  
  // Äá»c metadata Ä‘á»ƒ biáº¿t sá»‘ lÆ°á»£ng URLs
  const metadata = JSON.parse(fs.readFileSync(path.join('chunks','metadata.json'), 'utf8'));
  console.log(`âœ… Äá»c ${metadata.totalUrls} URLs tá»« Excel file`);
  return metadata.totalUrls;
}

async function splitUrlsForReliability() {
  console.log('2ï¸âƒ£ Splitting URLs cho Ä‘á»™ tin cáº­y cao...');
  
  // Äá»c metadata Ä‘Ã£ cÃ³
  const metadata = JSON.parse(fs.readFileSync(path.join('chunks','metadata.json'), 'utf8'));
  console.log(`Total URLs found: ${metadata.totalUrls}`);
  
  // Tá»‘i Æ°u chunk size cho Ä‘á»™ tin cáº­y (thay vÃ¬ tá»‘c Ä‘á»™)
  const chunkSize = 2; // 2 URLs per chunk Ä‘á»ƒ giáº£m failed chunks
  const numberOfChunks = Math.ceil(metadata.totalUrls / chunkSize);
  
  console.log(`Splitting into ${numberOfChunks} chunks, ${chunkSize} URLs per chunk (OPTIMIZED FOR RELIABILITY)`);
  
  // Äá»c táº¥t cáº£ URLs tá»« cÃ¡c chunk hiá»‡n táº¡i
  const allUrls = [];
  for (let i = 1; i <= metadata.numberOfChunks; i++) {
    const chunkFile = path.join(__dirname, 'chunks', `chunk-${i}.json`);
    if (fs.existsSync(chunkFile)) {
      const chunkUrls = JSON.parse(fs.readFileSync(chunkFile, 'utf8'));
      allUrls.push(...chunkUrls);
    }
  }
  
  // Táº¡o thÆ° má»¥c chunks má»›i
  const chunksDir = path.join(__dirname, 'chunks');
  
  // XÃ³a táº¥t cáº£ chunk files cÅ© trÆ°á»›c khi táº¡o má»›i
  console.log('ğŸ§¹ Cleaning up old chunk files...');
  for (let i = 1; i <= metadata.numberOfChunks; i++) {
    const oldChunkFile = path.join(chunksDir, `chunk-${i}.json`);
    if (fs.existsSync(oldChunkFile)) {
      fs.unlinkSync(oldChunkFile);
    }
  }
  
  // Split láº¡i thÃ nh chunks tá»‘i Æ°u cho Ä‘á»™ tin cáº­y
  const chunks = [];
  for (let i = 0; i < allUrls.length; i += chunkSize) {
    chunks.push(allUrls.slice(i, i + chunkSize));
  }
  
  // LÆ°u tá»«ng chunk vÃ o file riÃªng biá»‡t
  chunks.forEach((chunk, index) => {
    const chunkFile = path.join(chunksDir, `chunk-${index + 1}.json`);
    fs.writeFileSync(chunkFile, JSON.stringify(chunk, null, 2));
    console.log(`Created chunk-${index + 1}.json with ${chunk.length} URLs`);
  });
  
  // LÆ°u metadata vá» chunks má»›i
  const newMetadata = {
    totalUrls: allUrls.length,
    numberOfChunks: chunks.length,
    chunkSize: chunkSize,
    chunks: chunks.map((chunk, index) => ({
      chunkNumber: index + 1,
      urlCount: chunk.length,
      filename: `chunk-${index + 1}.json`
    }))
  };
  
  fs.writeFileSync(
    path.join(chunksDir, 'metadata.json'),
    JSON.stringify(newMetadata, null, 2)
  );
  
  console.log('URL splitting completed successfully!');
  console.log(`Metadata saved to chunks/metadata.json`);
  
  return chunks.length;
}

function runChunk(i) {
  return new Promise((resolve, reject) => {
    console.log(`â†’ Forking chunk ${i}â€¦`);
    const cp = fork(path.join(__dirname, 'helpers', 'process-chunk.js'), [String(i)], { 
      stdio: 'inherit',
      timeout: 180000 // 3 minutes timeout per chunk (tÄƒng lÃªn cho Ä‘á»™ tin cáº­y)
    });
    
    cp.on('exit', code => {
      if (code === 0) {
        console.log(`âœ… Chunk ${i} completed successfully`);
        resolve(i);
      } else {
        console.error(`âŒ Chunk ${i} failed with exit code ${code}`);
        reject(new Error(`Chunk ${i} failed (exit ${code})`));
      }
    });
    
    cp.on('error', (error) => {
      console.error(`âŒ Chunk ${i} error:`, error.message);
      reject(error);
    });
  });
}

async function mergeResults() {
  console.log('\n4ï¸âƒ£ Testing results merging...');
  require('child_process').execSync('npm run merge', { stdio: 'inherit' });
  const summary = JSON.parse(fs.readFileSync(path.join('report','summary.json'), 'utf8'));
  console.log(`âœ… Merge: ${summary.processedUrls}/${summary.totalUrls} URLs (${summary.successRate})`);
  console.log(`â± totalTime (from summary): ${summary.totalTime}`);
}

async function main() {
  console.log('ğŸš€ Testing Optimized Parallel Processing for URLs from Excel...\n');
  
  try {
    // 1. Táº¡o test data tá»‘i Æ°u
    const urlCount = await createOptimizedTestData();

    // 2. Split
    const chunkCount = await splitUrlsForReliability();

    // 3. Process all chunks in parallel vá»›i timeout vÃ  retry
    console.log('\n3ï¸âƒ£ Processing chunks in PARALLEL (OPTIMIZED FOR RELIABILITY)...');
    const start = Date.now();
    
    // ThÃªm retry mechanism cho failed chunks
    const maxRetries = 2;
    const chunkResults = new Array(chunkCount).fill(null);
    
    for (let retry = 0; retry <= maxRetries; retry++) {
      if (retry > 0) {
        console.log(`\nğŸ”„ Retry attempt ${retry}/${maxRetries} for failed chunks...`);
      }
      
      const chunkPromises = Array.from({ length: chunkCount }, (_, idx) => {
        const chunkIndex = idx + 1;
        if (chunkResults[idx] !== null) {
          // Chunk Ä‘Ã£ thÃ nh cÃ´ng, bá» qua
          return Promise.resolve(chunkIndex);
        }
        
        return runChunk(chunkIndex)
          .then(result => {
            chunkResults[idx] = result;
            return result;
          })
          .catch(error => {
            console.error(`Chunk ${chunkIndex} failed:`, error.message);
            return null;
          });
      });
      
      const results = await Promise.all(chunkPromises);
      
      // Kiá»ƒm tra xem cÃ³ chunk nÃ o cÃ²n failed khÃ´ng
      const failedChunks = chunkResults.filter(result => result === null).length;
      if (failedChunks === 0) {
        console.log(`âœ… All chunks completed successfully!`);
        break;
      } else if (retry < maxRetries) {
        console.log(`âš ï¸  ${failedChunks} chunks still failed, will retry...`);
        await new Promise(resolve => setTimeout(resolve, 5000)); // Wait 5s before retry
      }
    }
    
    const successfulChunks = chunkResults.filter(result => result !== null);
    
    const end = Date.now();
    const parallelTime = ((end - start) / 1000).toFixed(2);
    
    console.log(`\nâœ… Processing completed in ${parallelTime}s`);
    console.log(`ğŸ“Š Successful chunks: ${successfulChunks.length}/${chunkCount}`);
    console.log(`ğŸ“Š Failed chunks: ${chunkCount - successfulChunks.length}`);

    // 4. Merge & final check
    await mergeResults();

    console.log('\nğŸ‰ Optimized test completed!');
    console.log(`ğŸ“Š Processed ${urlCount} URLs in ${parallelTime}s`);
    console.log(`ğŸ“Š Success rate: ${((successfulChunks.length / chunkCount) * 100).toFixed(2)}%`);
    
  } catch (error) {
    console.error('\nâŒ Test failed:', error.message);
    process.exit(1);
  }
}

main();